{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing cloud-top phase retrievals\n",
    "New data from Olimpia (through Trude) is organized differently. I need to write it to a .nc format so I can make quick comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add common resources folder to path\n",
    "sys.path.append(\"/mnt/mcc-ns9600k/jonahks/git_repos/netcdf_analysis/Common/\")\n",
    "sys.path.append(\"/mnt/mcc-ns9600k/jonahks/git_repos/netcdf_analysis/\")\n",
    "sys.path.append(\"/home/jonahks/git_repos/netcdf_analysis/\")\n",
    "sys.path.append(\"/home/jonahks/git_repos/netcdf_analysis/Common/\")\n",
    "\n",
    "from imports import (\n",
    "    pd, np, xr, mpl, plt, sns, os, \n",
    "    datetime, sys, crt, gridspec,\n",
    "    polyfit, ccrs, LinearRegression, metrics,\n",
    "    datetime\n",
    "    )\n",
    "\n",
    "from functions import (\n",
    "    masked_average, plot_slf_isotherms,\n",
    "    season_mean, add_weights\n",
    "    )\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running through MC2 Jupyter Hub\n",
      "Can access all directory paths: True\n"
     ]
    }
   ],
   "source": [
    "host = os.uname()[1]\n",
    "if 'jupyter' in host.split('-'): # Check if running on NIRD through the Jupyter Hub\n",
    "    print('Running through MC2 Jupyter Hub')\n",
    "    model_dir = '/mnt/mcc-ns9600k/jonahks/'\n",
    "    os.chdir(model_dir)\n",
    "\n",
    "else:  # Assume that we're running on a local machine and mounting NIRD\n",
    "    print('Running on %s, attempting to mount ns9600k/jonahks/ from NIRD' % str(host))\n",
    "    os.system('fusermount -zu ~/drivemount/')  # unmount first\n",
    "    os.system('sshfs jonahks@login.nird.sigma2.no:\"p/jonahks/\" ~/drivemount/')    # Calling mountnird from .bashrc doesn't work\n",
    "    os.chdir('/home/jonahks/drivemount/')\n",
    "    save_dir = '~/DATAOUT/'\n",
    "    save_to = os.path.expanduser(save_dir)\n",
    "\n",
    "bulk_obs_dir = \"caliop_olimpia/4_Jonah/bulk3/season/global/\"\n",
    "top_obs_dir = 'caliop_olimpia/4_Jonah/top03/season/global/'\n",
    "\n",
    "output_dir = 'caliop_olimpia/seasonal_data/'\n",
    "model_dir = 'mnth15runs/'   # inconsistent label compared to jupy_test\n",
    "\n",
    "# Check that each important directory can be accessed:    \n",
    "access_paths = os.path.exists(bulk_obs_dir) and os.path.exists(top_obs_dir) and os.path.exists(output_dir)\n",
    "print('Can access all directory paths:', access_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load incloud/bulk cloud values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['read_me.txt', 'SON', 'JJA', 'MAM', 'DJF']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(bulk_obs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DJF 2010-01-01 00:00:00\n",
      "slf_count_geo_bulk_DJF.npz\n",
      "JJA 2010-07-01 00:00:00\n",
      "slf_count_geo_bulk_JJA.npz\n",
      "MAM 2010-04-01 00:00:00\n",
      "slf_count_geo_bulk_MAM.npz\n",
      "SON 2010-10-01 00:00:00\n",
      "slf_count_geo_bulk_SON.npz\n"
     ]
    }
   ],
   "source": [
    "df = np.zeros((180, 360, 9, 4)) # lat, lon, iso, season\n",
    "\n",
    "lat = np.linspace(-89.5, 89.5, 180)\n",
    "lon = np.linspace(-180, 179, 360)\n",
    "iso = np.linspace(0, -40, 9)\n",
    "time = [datetime(2010, 1, 1),datetime(2010, 7, 1),datetime(2010, 4, 1),datetime(2010, 10, 1)]\n",
    "season = ['DJF', 'JJA', 'MAM', 'SON'] # weird order\n",
    "season_dict = {'DJF':datetime(2010, 1, 15), 'JJA':datetime(2010, 7, 15), \n",
    "               'MAM':datetime(2010, 4, 15), 'SON':datetime(2010, 10, 15)} # by middle month\n",
    "\n",
    "cal_seasons = os.listdir(bulk_obs_dir)\n",
    "cal_seasons.sort()\n",
    "for i,season in enumerate(cal_seasons):\n",
    "    if len(season) == 3: # quickly filter out the README\n",
    "        print(season, time[i])\n",
    "        obs_files = os.listdir(\"%s%s\" % (bulk_obs_dir,season))\n",
    "        file_str = '.npz'\n",
    "        data_file = [x for x in obs_files if file_str in x][0] # weird list/indexing things :(\n",
    "        print(data_file)\n",
    "        _npz = np.load('%s%s/%s' % (bulk_obs_dir,season,data_file))\n",
    "        _slf_in = _npz[\"slf_geo\"]\n",
    "        _slf_out = np.moveaxis(_slf_in, 0, -1)\n",
    "        \n",
    "        df[:,:,:,i] = _slf_out\n",
    "\n",
    "da = xr.DataArray(data=df,\n",
    "                  coords={\"lat\": lat,\n",
    "                          \"lon\": lon,\n",
    "                          \"isotherm\": iso,\n",
    "                          \"time\": time},\n",
    "                  dims=[\"lat\",\"lon\", \"isotherm\",\"time\"])\n",
    "da = da.sortby('isotherm')\n",
    "\n",
    "da.attrs['long_name'] = \"SLF retrieved by CALIOP from within cloud (TAU: 0.0-3.0) \"\n",
    "da.attrs['units'] = \"Fraction [0-1]\"\n",
    "\n",
    "ds = xr.Dataset()\n",
    "ds['SLF'] = da\n",
    "ds = add_weights(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(path='%s/incloud_slfs_seasonal.nc' % output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cloudtop slf values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DJF 2010-01-01 00:00:00\n",
      "slf_count_geo_DJF.npz\n",
      "JJA 2010-07-01 00:00:00\n",
      "slf_count_geo_JJA.npz\n",
      "MAM 2010-04-01 00:00:00\n",
      "slf_count_geo_MAM.npz\n",
      "SON 2010-10-01 00:00:00\n",
      "slf_count_geo_SON.npz\n"
     ]
    }
   ],
   "source": [
    "df = np.zeros((180, 360, 9, 4)) # lat, lon, iso, season\n",
    "\n",
    "lat = np.linspace(-89.5, 89.5, 180)\n",
    "lon = np.linspace(-180, 179, 360)\n",
    "iso = np.linspace(0, -40, 9)\n",
    "time = [datetime(2010, 1, 1),datetime(2010, 7, 1),datetime(2010, 4, 1),datetime(2010, 10, 1)]\n",
    "season = ['DJF', 'JJA', 'MAM', 'SON'] # weird order\n",
    "season_dict = {'DJF':datetime(2010, 1, 15), 'JJA':datetime(2010, 7, 15), \n",
    "               'MAM':datetime(2010, 4, 15), 'SON':datetime(2010, 10, 15)} # by middle month\n",
    "\n",
    "cal_seasons = os.listdir(top_obs_dir)\n",
    "cal_seasons.sort()\n",
    "for i,season in enumerate(cal_seasons):\n",
    "    if len(season) == 3: # quickly filter out the README\n",
    "        print(season, time[i])\n",
    "        obs_files = os.listdir(\"%s%s\" % (top_obs_dir,season))\n",
    "        file_str = '.npz'\n",
    "        data_file = [x for x in obs_files if file_str in x][0] # weird list/indexing things :(\n",
    "        print(data_file)\n",
    "        _npz = np.load('%s%s/%s' % (top_obs_dir,season,data_file))\n",
    "        _slf_in = _npz[\"slf_geo\"]\n",
    "        _slf_out = np.moveaxis(_slf_in, 0, -1)\n",
    "        \n",
    "        df[:,:,:,i] = _slf_out\n",
    "\n",
    "da = xr.DataArray(data=df,\n",
    "                  coords={\"lat\": lat,\n",
    "                          \"lon\": lon,\n",
    "                          \"isotherm\": iso,\n",
    "                          \"time\": time},\n",
    "                  dims=[\"lat\",\"lon\", \"isotherm\",\"time\"])\n",
    "da = da.sortby('isotherm')\n",
    "\n",
    "da.attrs['long_name'] = \"SLF retrieved by CALIOP from the top lower discarding TAU < 0.3) \"\n",
    "da.attrs['units'] = \"Fraction [0-1]\"\n",
    "\n",
    "ds = xr.Dataset()\n",
    "ds['SLF'] = da\n",
    "ds = add_weights(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(path='%s/cloudtop_slfs_seasonal.nc' % output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting that the SLF at the -10C isotherm is latitude dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
